doctype html
html
    head
        meta(charset="utf-8")
        meta(name="viewport", content="initial-scale=1, maximum-scale=1, user-scalable=no, width=device-width")
        meta(name="apple-mobile-web-app-capable", content="yes")
        meta(name="apple-mobile-web-app-status-bar-style", content="black")
        meta(http-quiv="X-UA-Compatible", content="IE=edge,chrome=1")
        meta(name="description", content="#{__('在线可视化体验 ID3 分类算法.')}")
        title #{__('ID3 分类算法可视化')}
        link(rel="shortcut icon", href="/favicon.ico")
        style(type="text/css").
            @font-face {
                font-family: 'Droid Serif';
                src: url("/assets/fonts/DroidSerif.ttf");
            }
            @font-face {
                font-family: 'Yanone Kaffeesatz';
                src: url('/assets/fonts/Yanone_Kaffeesatz/YanoneKaffeesatz-Regular.ttf')
            }
            @font-face {
                font-family: 'Ubuntu Mono';
                src: url('/assets/fonts/Ubuntu_Mono/UbuntuMono-Regular.ttf')
            }

            body {
                font-family: 'Droid Serif';
            }

            h1, h2, h3 {
                font-family: 'Yanone Kaffeesatz';
                font-weight: normal;
            }

            .remark-code, .remark-inline-code {
                font-family: 'Ubuntu Mono';
            }

            .inverse {
                background: #272822;
                color: #777872;
                text-shadow: 0 0 20px #333;
            }

            .inverse h1, .inverse h2 {
                color: #f3f3f3;
                line-height: 0.8em;
            }

            .white { color: white; }

            .footnote {position: absolute; bottom: 3em;}


body
    textarea#source.
        class: center, middle

        # [id3](https://en.wikipedia.org/wiki/ID3_algorithm)
        ## 决策树构建算法介绍

        ---

        background-image: url(/assets/images/decision-tree.jpg)
        background-position: center bottom

        # 背景

        在做决策时，我们通常会考量多个因素。如果要将这个决策逻辑表达出来，我们很可能会采用画一个决策流程图的方式。这种决策流程图，因为结构上很类似一棵树，我们称它为决策树。

        ---

        background-image: url(/assets/images/data.png)
        background-position: center bottom
        background-size: 80%

        # 问题

        给定一组训练数据集和决策结果，如何让计算机学会画决策树？

        ---

        class: center, middle

        # 难点

        - 属性众多，该先选哪个，再选哪个？

        ---

        # 启示

        - 优先选择给我们信息量更大的属性

        # 问题

        - 怎么衡量和计算每个属性的信息量？

        ---

        background-image: url(/assets/images/k8s_is_simple.jpeg)
        background-position: center bottom
        background-size: cover

        class: left bottom

        # .white[呼唤天才]

        .white[信息量的计算非常简单，只是需要一个天才来理解信息量而已。]

        ---

        class: left, top

        background-image: url(/assets/images/ClaudeShannon_MFO3807.jpg)
        background-position: right bottom
        background-size: contain

        # 什么是信息？

        信息是用来消除随机不确定性的东西。
        .right.white[—— 香农]

        .footnote[By Jacobs, Konrad - <a rel="nofollow" class="external free" href="https://opc.mfo.de/detail?photo_id=3807">https://opc.mfo.de/detail?photo_id=3807</a>, <a href="https://creativecommons.org/licenses/by-sa/2.0/de/deed.en" title="Creative Commons Attribution-Share Alike 2.0 de">CC BY-SA 2.0 de</a>, <a href="https://commons.wikimedia.org/w/index.php?curid=45380422">Link</a>]
        ---

        class: center, middle

        # 信息熵

        $$H=-\sum_{i} p_i log_2(p_i)$$

        ---

        class: left, top

        background-image: url(/assets/images/data.png), url(/assets/images/800px-Binary_entropy_plot.svg.png)
        background-position: left bottom, right bottom
        background-size: 50%, 35%

        # 对于二元分类的例子

        $$H=-p\_\oplus log\_2(p\_\oplus)-p\_\ominus log\_2(p\_\ominus)$$

        |Total | Yes | No |
        | ---- | --- | -- |
        | 14   | 9   | 5  |

        $$H=-\frac{5}{14} log\_2(\frac{5}{14}) - \frac{9}{14} log\_2(\frac{9}{14})=0.9402859586706309$$

        ---

        class: left, top

        # 信息增益

        信息增益 = 熵（前）-熵（后）

        $$Gain(D, A) = H(D) - H(D|A)$$

        **做法**：计算使用所有特征划分数据集D，得到多个特征划分数据集D的信息增益，从这些信息增益中选择最大的，因而当前结点的划分特征便是使信息增益最大的划分所使用的特征。

        ---

        class: left, middle

        background-image: url(/assets/images/Richard_Feynman_Nobel.jpg)
        background-position: right bottom
        background-size: contain

        # [Richard Feynman](https://en.wikipedia.org/wiki/Richard_Feynman)
        > 我不能创造的，我就并不理解。

        ---

        class: center, middle

        # https://id3.js.org

        ---

        class: left, middle

        # 局限

        - ID3 算法的实际上是在众多的决策树空间中，以信息增益最大为优先原则搜索决策树。
        - 容易得到局部最优解

        ---

        class: left, middle

        # 关于奥坎姆剃刀原则

        ## 为什么我们偏爱于更短的决策树？

        如果使用冗长的决策树来得到最终的决策，即使它很好地拟合了训练数据，但也可能是一种巧合造成的。 如果非常简短的决策树便能很好地拟合训练数据，那么这更加可能不是巧合，而是这几个关键属性与最终结果有着某种更强烈的联系。

div
    script(src="/assets/scripts/remark.min.js")
    script(src="/lib/katex/dist/katex.min.js")
    script(src="/lib/katex/dist/contrib/auto-render.min.js")
    link(rel="stylesheet", href="/lib/katex/dist/katex.min.css")
    script.
        var options = {};
        var renderMath = function() {
            renderMathInElement(document.body);
            // or if you want to use $...$ for math,
            // renderMathInElement(document.body, {delimiters: [ // mind the order of delimiters(!?)
            //     {left: "$$", right: "$$", display: true},
            //     {left: "$", right: "$", display: false},
            //     {left: "\\[", right: "\\]", display: true},
            //     {left: "\\(", right: "\\)", display: false},
            // ]});
        }

        var slideshow = remark.create(options, renderMath);
